{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Desarrollo de una Red Neuronal con el lenguaje de Programación Python.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>1.- Creamos la clase NeuralNetwork en Python para entrenar a la neurona y dar una predicción precisa. La clase también tendrá otras funciones auxiliares. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La biblioteca numpy servirá para realizar los cálculos del programa. Esta viene con los siguientes cuatro métodos importantes:<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exp:** para generar el exponencial natural<br>\n",
    "**array:** para generar una matriz<br>\n",
    "**dot:** para multiplicar matrices<br>\n",
    "**random:** para generar números aleatorios. Tenga en cuenta que sembrarán los números aleatorios para garantizar su distribución eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>2.- Utilizamos la función Sigmoide \n",
    "Vamos a utilizar la función Sigmoide, que dibuja una curva característica en forma de \"S\", como una función de activación de la red neuronal.\n",
    "Esta función puede asignar cualquier valor entre de 0 a 1. Nos ayudará a normalizar la suma ponderada de las entradas.</p>\n",
    "\n",
    "Posteriormente, crearemos una función para calcular la derivada de la función Sigmoide y ayudar a calcular los ajustes esenciales de los pesos.\n",
    "\n",
    "La salida de una función Sigmoide se puede emplear para generar su derivada. Por ejemplo, si la variable de salida es \"x\", entonces su derivada será x * (1-x).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Entrenamos el modelo \n",
    "En esta parte enseñaremos a la red neuronal a hacer una predicción precisa. Cada entrada tendrá un peso, ya sea positivo o negativo.\n",
    "\n",
    "Esto implica que una entrada que tenga una gran cantidad de peso positivo o una gran cantidad de peso negativo influirá más en la salida resultante.\n",
    "\n",
    "Recordar que inicialmente comenzamos asignando cada peso a un número aleatorio.\n",
    "\n",
    "Procedimiento para el proceso de entrenamiento que usamos en esta red neuronal:\n",
    "\n",
    "**1** Tomamos las entradas del conjunto de datos de entrenamiento, realizamos algunos ajustes basados en sus pesos y los desviamos mediante un método que calculó la salida de la RN.\n",
    "**2** Calculamos la tasa de error propagada hacia atrás. En este caso, es la diferencia entre la salida prevista de la neurona y la salida esperada del conjunto de datos de entrenamiento.\n",
    "**3** Según la extensión del error obtenido, realizamos algunos ajustes menores de peso utilizando la fórmula Derivada ponderada por error.\n",
    "**4** Repetimos este proceso un número arbitrario de 15,000 veces. En cada iteración, todo el conjunto de entrenamiento se procesa simultáneamente.\n",
    "**5** Utilizamos la función \".T\" para transponer la matriz de la posición horizontal a la posición vertical. Por lo tanto, los números se almacenarán de una manera matricial\n",
    "\n",
    "\n",
    "Finalmente, los pesos de la neurona se optimizarán para los datos de entrenamiento proporcionados. En consecuencia, si se hace que la neurona piense en una nueva situación, que es la misma que la anterior, podría hacer una predicción precisa. Así es como tiene lugar la propagación hacia atrás.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la libreria numpy con un alias\n",
    "import numpy as np\n",
    "\n",
    "# Definimos nuestra clase principal\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "\n",
    "    # Constructor de la clase\n",
    "    # Todas las clases en Python tienen que recibir este parametro\n",
    "    def __init__(self):\n",
    "        # Utiliamos seed para la generacion de valores randomicos\n",
    "        np.random.seed(1)\n",
    "\n",
    "        # Convertimos los pesos a una matriz de 3 por 1 con los valores de -1 a 1\n",
    "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "    # Funcion sigmoide\n",
    "    def sigmoid(self, x):\n",
    "        # Aplicamos la funcion sigmoide\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Derivamos el valor de la funcion sigmoide\n",
    "    def sigmoid_derivative(self, x):\n",
    "        # Calculamos la derivada\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # Entrenamos a la red neuronal a través de un proceso de prueba y error\n",
    "    # Se realiza un ajuste de los pesos sinápticos cada vez.\n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "\n",
    "        # Entrenamos el modelo para hacer predicciones mientras se ajustan los pesos continuamente\n",
    "        for iteration in range(training_iterations):\n",
    "            # Pasar el conjunto de entrenamiento a través de nuestra red neuronal (una sola neurona\n",
    "            output = self.think(training_inputs)\n",
    "\n",
    "            # Calcular el error(La diferencia entre el resultado deseado y el resultado obtenido\n",
    "            error = training_outputs - output\n",
    "\n",
    "            # Multiplica el error por la entrada y nuevamente por el gradiente de la curva Sigmoid\n",
    "            # Esto significa que los pesos menos confiables se están ajustando más\n",
    "            # Esto significa que las entradas que son cero, no causan cambios en los pesos.\n",
    "            adjustments = np.dot(training_inputs.T, error *\n",
    "                                 self.sigmoid_derivative(output))\n",
    "\n",
    "            # Ajuste de los pesos\n",
    "            self.synaptic_weights += adjustments\n",
    "\n",
    "    # La red neuronal piensa\n",
    "    def think(self, inputs):\n",
    "        # Pasar las entradas a través de nuestra red neuronal (una neurona)\n",
    "        # Convertimos los valores a flotantes\n",
    "\n",
    "        inputs = inputs.astype(float)\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return output\n",
    "\n",
    "\n",
    "# Función de entrada\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Iniciar una red neuronal de una neurona\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    print(\"Pesos iniciales generados al azar: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    # El conjunto de pruebas. Tenemos cuatro ejemplos, cada uno consiste en 3 valores de entrada\n",
    "    # y un valor de salida.\n",
    "    training_inputs = np.array([[0, 0, 1],\n",
    "                                [1, 1, 1],\n",
    "                                [1, 0, 1],\n",
    "                                [0, 1, 1]])\n",
    "\n",
    "    training_outputs = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "    # Entrenar la red neuronal utilizando el conjunto de entrenamiento.\n",
    "    # Realizar 10000 veces y realizar un ajuste más pequeño cada vez.\n",
    "    neural_network.train(training_inputs, training_outputs, 15000)\n",
    "\n",
    "    print(\"Terminamos el proceso de pesos después del entrenamiento: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    user_input_one = str(input(\"Entrada #1: \"))\n",
    "    user_input_two = str(input(\"Entrada #2: \"))\n",
    "    user_input_three = str(input(\"Entrada #3: \"))\n",
    "\n",
    "    # Prueba la red neuronal con una nueva situación\n",
    "    print(\"Consideramos una nueva situación: \", user_input_one,\n",
    "          user_input_two, user_input_three)\n",
    "    print(\"Nueva entrada de datos: \")\n",
    "    print(neural_network.think(\n",
    "        np.array([user_input_one, user_input_two, user_input_three])))\n",
    "    print(\"Hecho!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Resultado por consola:</p>\n",
    "\n",
    "<p>Pesos iniciales generados al azar:</p>\n",
    "<p>[[-0.16595599]</p>\n",
    "<p> [ 0.44064899]</p>\n",
    "<p> [-0.99977125]]</p>\n",
    "<p>Terminamos el proceso de pesos después del entrenamiento: </p>\n",
    "<p>[[10.08740896]</p>\n",
    "<p> [-0.20695366]</p>\n",
    "<p> [-4.83757835]]</p>\n",
    "<p>Entrada #1: 5</p>\n",
    "<p>Entrada #2: 2</p>\n",
    "<p>Entrada #3: 1</p>\n",
    "<p>Consideramos una nueva situación:  5 2 1</p>\n",
    "<p>Nueva entrada de datos:</p> \n",
    "<p>[1.]</p>\n",
    "<p>Hecho!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**CONCLUSIONES**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Se ha logrado crear una Red Neuronal Básica\n",
    "La neurona comenzó con la asigación de algunos pesos al azar. Posteriormente, se entrenó a sí misma utilizando los ejemplos de entrenamiento.\n",
    "\n",
    "En consecuencia, si se le presentaba una nueva situación [1,0,0], daba el valor de 0.9999584.\n",
    "\n",
    "Ojo: La respuesta correcta deseada era 1, entonces, eso está muy cerca, considerando que la función Sigmoide genera valores entre 0 y 1.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
